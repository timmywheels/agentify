import { Agentify } from "../core/agentify";

interface OpenAIOptions {
  apiKey: string;
  defaultModel?: string;
  organization?: string;
  maxTokens?: number;
  temperature?: number;
}

/**
 * A plugin that adds OpenAI capabilities to the framework
 */
function openaiPlugin(
  instance: ReturnType<typeof Agentify>,
  opts: OpenAIOptions
) {
  // Validate required options
  if (!opts.apiKey) {
    throw new Error("OpenAI plugin requires an API key");
  }

  // Default options
  const defaultOptions = {
    defaultModel: "gpt-3.5-turbo",
    maxTokens: 1000,
    temperature: 0.7,
    ...opts,
  };

  // Create namespace for OpenAI tools
  const openaiTools = instance.toolNamespace("openai");

  // Chat completion tool
  openaiTools.tool("completion", {
    description: "Generate text using OpenAI models",
    tags: ["llm", "text", "generation"],
    schema: {
      input: {
        type: "object",
        required: ["prompt"],
        properties: {
          prompt: { type: "string" },
          model: { type: "string", default: defaultOptions.defaultModel },
          maxTokens: { type: "number", default: defaultOptions.maxTokens },
          temperature: { type: "number", default: defaultOptions.temperature },
        },
      },
      output: {
        type: "string",
      },
    },
    use: async (input: {
      prompt: string;
      model?: string;
      maxTokens?: number;
      temperature?: number;
    }) => {
      const {
        prompt,
        model = defaultOptions.defaultModel,
        maxTokens = defaultOptions.maxTokens,
        temperature = defaultOptions.temperature,
      } = input;

      // Simplified mock implementation
      // In a real implementation, this would call the OpenAI API
      console.log(`Generating text with model: ${model}`);
      console.log(
        `Prompt: ${prompt.substring(0, 50)}${prompt.length > 50 ? "..." : ""}`
      );
      console.log(
        `Parameters: maxTokens=${maxTokens}, temperature=${temperature}`
      );

      // Mock response based on the prompt
      const mockCompletion = () => {
        if (prompt.toLowerCase().includes("facts")) {
          return [
            "1. The average cloud weighs around 1.1 million pounds.",
            "2. Honey never spoils - archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old.",
            "3. The shortest war in history was between Britain and Zanzibar in 1896, lasting only 38 minutes.",
          ].join("\n");
        } else if (prompt.toLowerCase().includes("summarize")) {
          return "This is a concise summary of the provided information, highlighting the key points and main ideas while omitting unnecessary details.";
        } else {
          return `Here is a response to your prompt about ${prompt
            .split(" ")
            .slice(0, 3)
            .join(
              " "
            )}... The response continues with relevant information generated by the model based on the input prompt.`;
        }
      };

      // Simulate API delay
      await new Promise((resolve) => setTimeout(resolve, 500));

      return mockCompletion();
    },
  });

  // Summarization tool
  openaiTools.tool("summarize", {
    description: "Summarize text content",
    tags: ["llm", "text", "summarization"],
    schema: {
      input: {
        type: "object",
        required: ["text"],
        properties: {
          text: { type: "string" },
          maxLength: { type: "number", default: 200 },
          model: { type: "string", default: defaultOptions.defaultModel },
        },
      },
      output: {
        type: "string",
      },
    },
    use: async (input: {
      text: string;
      maxLength?: number;
      model?: string;
    }) => {
      const {
        text,
        maxLength = 200,
        model = defaultOptions.defaultModel,
      } = input;

      // Simplified mock implementation
      console.log(
        `Summarizing text (${text.length} chars) to max length: ${maxLength}`
      );
      console.log(`Using model: ${model}`);

      // Mock summarization
      const summary = `This is a summary of the provided text, condensed to be concise and informative. 
      The original text was about ${text.length} characters long and has been 
      reduced to focus on the key points while maintaining the most important information.`;

      // Simulate API delay
      await new Promise((resolve) => setTimeout(resolve, 300));

      return summary;
    },
  });

  // Add utility decorator to the main instance
  instance.decorate("openai", {
    generateText: async (prompt: string, options = {}) => {
      return instance.useTool("openai:completion", {
        prompt,
        ...options,
      });
    },
    summarize: async (text: string, maxLength?: number) => {
      return instance.useTool("openai:summarize", {
        text,
        maxLength,
      });
    },
  });

  // Log successful initialization
  instance.log?.info(
    "OpenAI plugin initialized with API key: " +
      opts.apiKey.substring(0, 3) +
      "..." +
      opts.apiKey.substring(opts.apiKey.length - 3)
  );

  // Return named plugin
  return {
    name: "openai",
    init: async () => {
      instance.log?.info("OpenAI plugin ready");
    },
  };
}

// Export the plugin
export default openaiPlugin;
