# AGENTIFY FRAMEWORK: COMPREHENSIVE CONTEXT

## SYSTEM_OVERVIEW
name: "agentify"
type: "TypeScript framework"
purpose: "Building, deploying, evaluating, and orchestrating agentic workflows"
architecture_style: "Plugin-based, declarative, composable"
inspiration: "Fastify web framework"
primary_language: "TypeScript"
license: "ISC"

## CORE_PRINCIPLES
- Declarative: Users specify what they want, not how to achieve it
- Composable: Complex systems built from simpler components
- Type-safe: Leveraging TypeScript's type system for safety
- Extensible: Plugin and hooks system for adding functionality
- Loosely coupled: Components interact through well-defined interfaces

## CORE_PRIMITIVES

### PRIMITIVE: TOOL
definition: "Self-contained function performing a specific, atomic operation"
responsibility: "Provide a single capability without decision-making logic"
is_stateless: true
input_type: "Defined by tool implementation"
output_type: "Defined by tool implementation"

characteristics:
- Single responsibility
- Stateless execution
- Pure input/output transformation
- No dependencies on other tools
- No orchestration or decision-making logic

interface:
```typescript
interface Tool {
  name: string;
  description: string;
  use: (input: any) => Promise<any>;
  inputSchema?: any; // JSON Schema or similar
  outputSchema?: any; // JSON Schema or similar
}
```

registration_example:
```typescript
app.tool("webSearch", {
  description: "Search the web for information",
  use: async (input: { query: string }) => {
    // Tool implementation
    const results = await someSearchProvider.search(input.query);
    return results;
  },
});
```

usage_example:
```typescript
// Within an agent
const searchResults = await tools.webSearch.use({ query: "quantum computing" });
```

### PRIMITIVE: AGENT
definition: "Autonomous entity that uses tools and reasoning to achieve goals"
responsibility: "Use tools to accomplish tasks requiring decision-making"
is_stateless: false
input_type: "AgentRequest"
output_type: "Response via AgentReply"

characteristics:
- Uses multiple tools to accomplish tasks
- Has defined capabilities
- Makes decisions about which tools to use
- Maintains conversation/execution state
- Handles errors and adapts to changing conditions
- Can be implemented with rule-based logic, LLMs, or hybrid approaches

interface:
```typescript
interface AgentOptions {
  name: string;
  capabilities: string[];
  execute: (request: AgentRequest, reply: AgentReply) => Promise<void>;
  description?: string;
  init?: () => Promise<void>;
  shutdown?: () => Promise<void>;
}

interface AgentRequest {
  body: any; // Input data
  tools: Record<string, Tool>; // Available tools
  task?: { name: string; [key: string]: any }; // Task information
  params?: Record<string, any>; // Additional parameters
}

interface AgentReply {
  send: (data: any) => void; // Send response
  error: (err: Error) => void; // Report error
  code: (statusCode: number) => AgentReply; // Set status code
}
```

registration_example:
```typescript
app.agent("researchAgent", {
  capabilities: ["research", "search", "analyze"],
  execute: async (request, reply) => {
    const { topic } = request.body;
    
    // Decision-making logic to determine search approach
    const searchResults = await request.tools.webSearch.use({ 
      query: topic 
    });
    
    // Process and analyze results
    const analysis = await request.tools.analyzeText.use({ 
      text: JSON.stringify(searchResults) 
    });
    
    // Send combined results
    reply.send({
      searchResults,
      analysis,
      topic
    });
  },
});
```

llm_implementation_example:
```typescript
app.agent("llmResearchAgent", {
  capabilities: ["research", "reasoning"],
  execute: async (request, reply) => {
    const { topic } = request.body;
    
    // Use LLM to plan research approach
    const plan = await llmProvider.createPlan({
      goal: `Research ${topic}`,
      availableTools: Object.keys(request.tools)
    });
    
    // Execute plan steps using tools
    const results = await executePlan(plan, request.tools);
    
    // Use LLM to synthesize final response
    const synthesis = await llmProvider.synthesize(results);
    
    reply.send(synthesis);
  },
});
```

### PRIMITIVE: TASK
definition: "Well-defined unit of work with explicit inputs and outputs"
responsibility: "Provide a reusable building block for workflows"
is_stateless: true
input_type: "Defined in task handler"
output_type: "Defined in task handler"

characteristics:
- Clear input/output contract
- Simple, focused responsibility
- Reusable across workflows
- Composable into larger operations
- Stateless execution

interface:
```typescript
interface TaskOptions {
  handler: (input: any, context: any) => Promise<any>;
  schema?: {
    input?: any;
    output?: any;
  };
  description?: string;
}

interface TaskInstance {
  name: string;
  execute: (input: any, context?: any) => Promise<any>;
  // Additional methods added by decorators
}
```

registration_example:
```typescript
app.task("fetchData", {
  handler: async (input, context) => {
    const { url, headers } = input;
    const response = await fetch(url, { headers });
    const data = await response.json();
    return { data, timestamp: Date.now() };
  },
});
```

usage_example:
```typescript
// Direct execution
const result = await app.executeTask("fetchData", { 
  url: "https://api.example.com/data",
  headers: { "Authorization": "Bearer token" } 
});
```

### PRIMITIVE: WORKFLOW
definition: "Orchestrated sequence of tasks with defined data flow"
responsibility: "Define execution order and data mapping between tasks"
is_stateless: false
input_type: "Defined by workflow inputs"
output_type: "Result of final task or specified output mapping"

characteristics:
- Defines execution order
- Maps inputs between steps
- Handles conditional branching
- Manages error handling and retries
- Tracks overall progress

interface:
```typescript
interface WorkflowOptions {
  description?: string;
  inputSchema?: any;
  outputSchema?: any;
}

interface WorkflowStepOptions {
  taskName: string;
  inputMap: Record<string, string | Function>;
  condition?: (context: any) => boolean;
  errorHandler?: (error: Error, context: any) => Promise<any>;
}

interface WorkflowInstance {
  name: string;
  task: (id: string, options: WorkflowStepOptions) => WorkflowInstance;
  sequence: (steps: string[]) => WorkflowInstance;
  condition: (id: string, options: ConditionOptions) => WorkflowInstance;
  execute: (input: any) => Promise<any>;
}
```

registration_example:
```typescript
const workflow = app
  .workflow("researchWorkflow")
  .description("Research a topic and synthesize findings")
  
  // Define steps with data mapping
  .task("search", {
    taskName: "fetchData",
    inputMap: {
      url: (context) => `https://api.search.com?q=${context.topic}`,
      headers: "headers",
    },
  })
  
  .task("analyze", {
    taskName: "analyzeData",
    inputMap: {
      data: "steps.search.data",
      depth: "analysisDepth",
    },
  })
  
  .task("synthesize", {
    taskName: "createSummary",
    inputMap: {
      analysis: "steps.analyze",
      format: "outputFormat",
    },
  })
  
  // Define conditional logic
  .condition("checkQuality", {
    condition: (context) => context.steps.analyze.confidence > 0.7,
    trueNext: "synthesize",
    falseNext: "deepSearch",
  })
  
  // Define execution order
  .sequence(["search", "analyze", "checkQuality"]);
```

execution_example:
```typescript
// Execute workflow
const result = await workflow.execute({
  topic: "Quantum Computing",
  headers: { "Authorization": "Bearer token" },
  analysisDepth: "deep",
  outputFormat: "markdown",
});
```

### PRIMITIVE: ORCHESTRATOR
definition: "Intelligent system that analyzes tasks and coordinates execution"
responsibility: "Decompose tasks, select agents, evaluate results"
is_stateless: false
input_type: "TaskDefinition and input data"
output_type: "Task execution result"

characteristics:
- Task decomposition and analysis
- Agent selection based on capabilities
- Result evaluation against criteria
- Retry management and failure handling
- Result aggregation and synthesis
- Potential use of LLMs for intelligent orchestration

interface:
```typescript
interface TaskDefinition {
  name: string;
  description: string;
  goal: string;
  input: Record<string, any>;
  expectedOutput?: {
    schema?: any;
    example?: any;
  };
  requiredCapabilities?: string[];
  evaluationCriteria?: {
    [criterion: string]: {
      description: string;
      threshold?: number;
    };
  };
  maxAttempts?: number;
}

interface OrchestratorOptions {
  defaultDecompositionStrategy?: DecompositionStrategy;
  enableAutoEvaluation?: boolean;
  evaluationThreshold?: number;
  maxRetries?: number;
  verbose?: boolean;
}

enum DecompositionStrategy {
  SEQUENTIAL = "sequential",
  PARALLEL = "parallel",
  RECURSIVE = "recursive",
  AUTO = "auto",
}

interface OrchestratorCore {
  executeTask: (taskDefinition: TaskDefinition, input: any) => Promise<any>;
}
```

usage_example:
```typescript
// Define task declaratively
const researchTask: TaskDefinition = {
  name: "researchTopic",
  description: "Research a topic thoroughly",
  goal: "Gather comprehensive information on a topic",
  requiredCapabilities: ["research", "analyze", "summarize"],
  input: {
    topic: "string",
    depth: "string?", // Optional
  },
  evaluationCriteria: {
    relevance: {
      description: "How relevant the research results are to the topic",
      threshold: 0.7,
    },
    completeness: {
      description: "How comprehensively the topic is covered",
      threshold: 0.8,
    },
  },
  maxAttempts: 3,
};

// Let the orchestrator handle execution
const result = await app.run(researchTask, { 
  topic: "Quantum Computing",
  depth: "academic" 
});
```

llm_enhanced_orchestrator:
```typescript
// The orchestrator can use LLMs for:
// 1. Task analysis
private async analyzeTask(taskDefinition: TaskDefinition) {
  return await llmService.analyzeTaskComplexity(taskDefinition);
}

// 2. Task decomposition
private async decomposeTask(taskDefinition: TaskDefinition) {
  return await llmService.breakDownIntoSubtasks(taskDefinition);
}

// 3. Agent selection
private async selectAgent(subtask: TaskDefinition) {
  return await llmService.findBestAgent(subtask, availableAgents);
}

// 4. Result evaluation
private async evaluateResult(result: any, criteria: any) {
  return await llmService.evaluateAgainstCriteria(result, criteria);
}

// 5. Result synthesis
private async aggregateResults(results: any[]) {
  return await llmService.synthesizeResults(results);
}
```

### PRIMITIVE: PLUGIN
definition: "Extension that adds new functionality to the framework"
responsibility: "Extend core framework with new features or integrations"
is_stateless: varies
input_type: "Plugin options"
output_type: "Enhanced framework functionality"

characteristics:
- Modifies or extends core framework behavior
- Adds new integrations (e.g., LLM providers, databases)
- Configures global settings
- Registers new tools, agents, or hooks
- Can affect multiple parts of the system

interface:
```typescript
interface PluginInstance {
  name: string;
  init?: (instance: Agentify, options: any) => Promise<void>;
  hooks?: Record<string, Function>;
  [key: string]: any;
}
```

registration_example:
```typescript
// Register an LLM provider plugin
app.register(require("agentify-openai"), {
  apiKey: process.env.OPENAI_API_KEY,
  defaultModel: "gpt-4",
  cacheResponses: true,
});
```

plugin_implementation_example:
```typescript
// OpenAI Plugin implementation
module.exports = function(fastify, opts, done) {
  // Validate options
  if (!opts.apiKey) {
    throw new Error('OpenAI API key is required');
  }
  
  // Initialize OpenAI client
  const openai = new OpenAI(opts.apiKey, {
    defaultModel: opts.defaultModel || 'gpt-3.5-turbo'
  });
  
  // Register tools provided by this plugin
  fastify.tool('openai.complete', {
    description: 'Generate text completion using OpenAI',
    use: async (input) => {
      return await openai.createCompletion(input);
    }
  });
  
  fastify.tool('openai.chat', {
    description: 'Generate chat completion using OpenAI',
    use: async (input) => {
      return await openai.createChatCompletion(input);
    }
  });
  
  // Add hooks
  fastify.addHook('onClose', async () => {
    // Cleanup
    await openai.close();
  });
  
  // Plugin initialization complete
  done();
};
```

## CORE_SYSTEMS

### SYSTEM: HOOK_SYSTEM
definition: "Event-based extension points throughout the framework lifecycle"
responsibility: "Allow custom logic at key execution points"

available_hooks:
- onTaskStart: Before a task executes
- onTaskEnd: After a task completes
- onAgentStart: Before an agent executes
- onAgentEnd: After an agent completes
- onWorkflowStart: Before a workflow executes
- onWorkflowEnd: After a workflow completes
- onEvaluationStart: Before result evaluation
- onEvaluationEnd: After result evaluation

usage_example:
```typescript
// Add a hook
app.addHook('onTaskEnd', async (task, result) => {
  // Log task execution time
  console.log(`Task ${task.name} completed in ${Date.now() - task.startTime}ms`);
});
```

### SYSTEM: LLM_INTEGRATION
definition: "Integration of Large Language Models throughout the framework"
responsibility: "Provide AI capabilities for reasoning, generation, and understanding"

integration_levels:
1. As tools (atomic capabilities):
   ```typescript
   app.tool("llm.generate", {
     description: "Generate text based on a prompt",
     use: async (input) => llmProvider.complete(input.prompt),
   });
   ```

2. Powering agents (decision-making):
   ```typescript
   app.agent("llmAgent", {
     capabilities: ["reasoning", "writing"],
     execute: async (request, reply) => {
       // Use LLM to determine how to use tools
       const plan = await llmService.createPlan(request.body.task);
       const result = await executePlan(plan, request.tools);
       reply.send(result);
     },
   });
   ```

3. In the orchestrator (task management):
   ```typescript
   // Used internally for task decomposition, agent selection,
   // result evaluation, and result synthesis
   ```

4. Provider plugins (system integration):
   ```typescript
   app.register(require("agentify-openai"), {
     apiKey: process.env.OPENAI_API_KEY,
   });
   ```

llm_abstraction_layer:
```typescript
interface LLMProvider {
  complete(prompt: string, options?: any): Promise<string>;
  chat(messages: any[], options?: any): Promise<any>;
  embed(text: string): Promise<number[]>;
}

interface LLMService {
  analyzeTask(taskDefinition: TaskDefinition): Promise<TaskAnalysis>;
  decomposeTask(taskDefinition: TaskDefinition): Promise<TaskDefinition[]>;
  selectAgent(task: TaskDefinition, agents: Agent[]): Promise<Agent>;
  evaluateResult(result: any, criteria: any): Promise<Evaluation>;
  synthesizeResults(results: any[]): Promise<any>;
}
```

## INTERACTIONS_AND_DATA_FLOW

### FLOW: TASK_EXECUTION
1. Task is registered with app.task()
2. Task is executed directly or via workflow
3. onTaskStart hooks execute
4. Task handler executes with input and context
5. Task handler returns result
6. onTaskEnd hooks execute
7. Result is returned or passed to next workflow step

### FLOW: AGENT_EXECUTION
1. Agent is registered with app.agent()
2. Agent is selected by orchestrator or called directly
3. onAgentStart hooks execute
4. Agent's execute method runs with request and reply
5. Agent uses tools to perform task
6. Agent calls reply.send() with result
7. onAgentEnd hooks execute
8. Result is returned to caller

### FLOW: WORKFLOW_EXECUTION
1. Workflow is defined with app.workflow()
2. Workflow execution is triggered with workflow.execute()
3. onWorkflowStart hooks execute
4. For each step in sequence:
   a. Input is mapped according to inputMap
   b. Task or agent is executed
   c. Result is stored in workflow context
   d. Conditional branches are evaluated
5. onWorkflowEnd hooks execute
6. Final result is returned

### FLOW: ORCHESTRATED_TASK_EXECUTION
1. Task definition is created
2. Task is submitted to orchestrator with app.run()
3. Orchestrator analyzes task
4. Task is decomposed into subtasks if needed
5. For each subtask:
   a. Appropriate agent is selected based on capabilities
   b. Agent is executed with required input
   c. Result is captured
6. Results are aggregated
7. Combined result is evaluated against criteria
8. If evaluation fails and retries remain, retry from step 3
9. Final result is returned

## IMPLEMENTATION_DETAILS

### DETAIL: TYPE_SAFETY
- TypeScript generics used throughout framework
- JSON Schema for runtime validation
- Interface definitions for all major components
- Type inference for improved developer experience

### DETAIL: PERFORMANCE_CONSIDERATIONS
- Lazy loading of components
- Caching of LLM responses
- Optimized agent selection
- Parallel execution where possible
- Resource usage monitoring

### DETAIL: EXTENSIBILITY_MECHANISMS
- Plugin system for adding new functionality
- Hooks for lifecycle events
- Decorators for enhancing components
- Custom task/agent implementations
- Provider abstraction for external services

### DETAIL: ERROR_HANDLING
- Structured error responses
- Retry mechanisms with backoff
- Fallback strategies
- Detailed logging
- Error aggregation and reporting

## CODE_EXAMPLES

### EXAMPLE: COMPLETE_RESEARCH_SYSTEM
```typescript
import { Agentify } from 'agentify';

// Initialize framework
const app = Agentify({ logger: true });

// Register OpenAI plugin
app.register(require('agentify-openai'), {
  apiKey: process.env.OPENAI_API_KEY,
});

// Define tools
app.tool('webSearch', {
  description: 'Search the web for information',
  use: async (input) => {
    // Implementation
  }
});

app.tool('contentExtractor', {
  description: 'Extract content from URLs',
  use: async (input) => {
    // Implementation
  }
});

// Define agents
app.agent('researchAgent', {
  capabilities: ['research', 'search'],
  execute: async (request, reply) => {
    const { topic } = request.body;
    const searchResults = await request.tools.webSearch.use({ query: topic });
    reply.send({ searchResults, topic });
  }
});

app.agent('contentAgent', {
  capabilities: ['extract', 'analyze'],
  execute: async (request, reply) => {
    const { searchResults } = request.body;
    const contents = await Promise.all(
      searchResults.map(result => 
        request.tools.contentExtractor.use({ url: result.url })
      )
    );
    reply.send({ contents });
  }
});

app.agent('llmSynthesisAgent', {
  capabilities: ['summarize', 'synthesize'],
  execute: async (request, reply) => {
    const { contents, topic } = request.body;
    const synthesis = await request.tools.openai.chat.use({
      messages: [
        { role: 'system', content: 'You are a research assistant.' },
        { role: 'user', content: `Synthesize this information about ${topic}: ${JSON.stringify(contents)}` }
      ]
    });
    reply.send({ synthesis, topic });
  }
});

// Define task declaratively
const researchTask = {
  name: 'comprehensiveResearch',
  description: 'Research a topic thoroughly',
  goal: 'Provide a comprehensive synthesis of information on a topic',
  requiredCapabilities: ['research', 'extract', 'synthesize'],
  input: {
    topic: 'string',
    depth: 'string?'
  },
  evaluationCriteria: {
    comprehensiveness: {
      description: 'How thoroughly the topic is covered',
      threshold: 0.8
    },
    clarity: {
      description: 'How clearly the information is presented',
      threshold: 0.7
    }
  }
};

// Execute the system
app.ready().then(async () => {
  try {
    const result = await app.run(researchTask, {
      topic: 'Quantum Computing',
      depth: 'advanced'
    });
    
    console.log('Research complete:');
    console.log(result.synthesis);
  } catch (error) {
    console.error('Research failed:', error);
  }
});
```

## LIMITATIONS_AND_CONSIDERATIONS

### LIMITATION: LLM_DEPENDENCIES
- LLM costs can accumulate with heavy usage
- API rate limits may affect performance
- Provider-specific limitations apply
- Output quality varies by model and provider
- Handling of sensitive information requires care

### LIMITATION: ORCHESTRATION_COMPLEXITY
- Complex decomposition may introduce overhead
- Agent selection heuristics may not be optimal
- Evaluation criteria may be subjective
- Retry strategies can be costly for expensive operations
- Debugging complex workflows requires specialized tools

### CONSIDERATION: EXTENDING_VS_USING
When to build a plugin vs. using existing components:
- Build plugin: Adding new system-level functionality
- Use components: Implementing domain-specific logic
- Consider hybrid: Extending components for specific domains

### CONSIDERATION: IMPLEMENTATION_CHOICES
Agent implementation approaches:
- Rule-based: For deterministic, predictable behavior
- LLM-based: For flexibility and reasoning capabilities
- Hybrid: For combining strengths of both approaches
- Specialized: For domain-specific optimizations

## DEVELOPMENT_AND_DEBUGGING

### DEBUGGING: VERBOSE_LOGGING
Enable verbose logging to trace execution:
```typescript
const app = Agentify({ 
  logger: true,
  logLevel: 'debug'
});
```

### DEBUGGING: STEP_EXECUTION
Execute workflow steps individually for debugging:
```typescript
const stepResult = await app.executeTask('taskName', input);
```

### DEBUGGING: MOCK_TOOLS
Create mock implementations for testing:
```typescript
app.tool('webSearch', {
  description: 'Search the web (mock)',
  use: async (input) => {
    return [
      { title: 'Mock result 1', url: 'https://example.com/1' },
      { title: 'Mock result 2', url: 'https://example.com/2' }
    ];
  }
});
```

## END_OF_DOCUMENT
